---
title: "TP 4 - Cr√©er une application multiconteneur"
draft: false
weight: 1045
---

## Articuler deux images avec Docker compose

<!-- ### Dans une VM -->

<!-- - Si Docker n'est pas d√©j√† install√©, installez Docker par la m√©thode officielle acc√©l√©r√©e et moins s√©curis√©e (un _one-liner‚Ñ¢_) avec `curl -fsSL https://get.docker.com -o get-docker.sh && sudo sh get-docker.sh`. Que fait cette commande ? Pourquoi est-ce moins s√©curis√© ? -->
<!-- - Installez VSCode avec la commande `sudo snap install --classic code` -->

- Installez docker-compose avec `sudo apt install docker-compose`.
  <!-- - S'il y a un bug  -->
  <!-- - S'ajouter au groupe `docker`avec `usermod -a -G docker stagiaire` et actualiser avec `newgrp docker stagiaire` -->

<!-- ### Avec Gitpod

`brew update` (si √ßa reste bloqu√© plus de 5min, arr√™tez avec Ctrl+C)
`brew install docker-compose`
Si la derni√®re commande ne marche pas, installez `docker-compose` de la fa√ßon suivante :

````bash
mkdir bin
curl -L "https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)" -o bin/docker-compose
chmod +x bin/docker-compose
export PATH="./bin:$PATH"
``` -->

### `identidock` : une application Flask qui se connecte √† `redis`

- D√©marrez un nouveau projet dans VSCode (cr√©ez un dossier appel√© `identidock` et chargez-le avec la fonction _Add folder to workspace_)
- Dans un sous-dossier `app`, ajoutez une petite application python en cr√©ant ce fichier `identidock.py` :

```python
from flask import Flask, Response, request
import requests
import hashlib
import redis

app = Flask(__name__)
cache = redis.StrictRedis(host='redis', port=6379, db=0)
salt = "UNIQUE_SALT"
default_name = 'Joe Bloggs'

@app.route('/', methods=['GET', 'POST'])
def mainpage():

    name = default_name
    if request.method == 'POST':
        name = request.form['name']

    salted_name = salt + name
    name_hash = hashlib.sha256(salted_name.encode()).hexdigest()
    header = '<html><head><title>Identidock</title></head><body>'
    body = '''<form method="POST">
                Hello <input type="text" name="name" value="{0}">
                <input type="submit" value="submit">
                </form>
                <p>You look like a:
                <img src="/monster/{1}"/>
            '''.format(name, name_hash)
    footer = '</body></html>'
    return header + body + footer


@app.route('/monster/<name>')
def get_identicon(name):

    image = cache.get(name)

    if image is None:
        print ("Cache miss", flush=True)
        r = requests.get('http://dnmonster:8080/monster/' + name + '?size=80')
        image = r.content
    cache.set(name, image)

    return Response(image, mimetype='image/png')

if __name__ == '__main__':
  app.run(debug=True, host='0.0.0.0', port=9090)

```

- `uWSGI` est un serveur python de production tr√®s adapt√© pour servir notre serveur int√©gr√© Flask, nous allons l'utiliser.

- Dockerisons maintenant cette nouvelle application avec le Dockerfile suivant :

```Dockerfile
FROM python:3.7

RUN groupadd -r uwsgi && useradd -r -g uwsgi uwsgi
RUN pip install Flask uWSGI requests redis
WORKDIR /app
COPY app/identidock.py /app

EXPOSE 9090 9191
USER uwsgi
CMD ["uwsgi", "--http", "0.0.0.0:9090", "--wsgi-file", "/app/identidock.py", \
"--callable", "app", "--stats", "0.0.0.0:9191"]
```

- Observons le code du Dockerfile ensemble s'il n'est pas clair pour vous. Juste avant de lancer l'application, nous avons chang√© d'utilisateur avec l'instruction `USER`, pourquoi ?.

- Construire l'application, pour l'instant avec `docker build`, la lancer et v√©rifier avec `docker exec`, `whoami` et `id` l'utilisateur avec lequel tourne le conteneur.

{{% expand "R√©ponse  :" %}}

- `docker build -t identidock .`
- `docker run --detach --name identidock -p 9090:9090 identidock`
- `docker exec -it identidock /bin/bash`

Une fois dans le conteneur lancez:

- `whoami` et `id`
- v√©rifiez aussi avec `ps aux` que le serveur est bien lanc√©.

{{% /expand %}}

<!-- - Validez la version actuelle du code avec Git en faisant : `git init && git add -A && git commit -m "Code initial pour le TP Docker Compose"` -->

<!-- ### Pousser notre image sur un registry (le Docker Hub)

- Si ce n'est pas d√©j√† fait, cr√©ez un compte sur `hub.docker.com`.
- Lancez `docker login` pour vous identifier en CLI.
- Donnons un tag avec votre login Docker Hub √† notre image pour pouvoir la pousser sur le registry : `docker tag identidock <votre_hub_login>/identidock:0.1`
- Puis poussons l'image sur le Docker Hub avec : `docker push <votre_hub_login>/identidock:0.1` -->

### Le fichier Docker Compose

- A la racine de notre projet `identidock` (√† c√¥t√© du Dockerfile), cr√©ez un fichier de d√©claration de notre application appel√© `docker-compose.yml` avec √† l'int√©rieur :

```yml
version: "3.7"
services:
  identidock:
    build: .
    ports:
      - "9090:9090"
```

- Plusieurs remarques :

  - la premi√®re ligne apr√®s `services` d√©clare le conteneur de notre application
  - les lignes suivantes permettent de d√©crire comment lancer notre conteneur
  - `build: .` indique que l'image d'origine de notre conteneur est le r√©sultat de la construction d'une image √† partir du r√©pertoire courant (√©quivaut √† `docker build -t identidock .`)
  - la ligne suivante d√©crit le mapping de ports entre l'ext√©rieur du conteneur et l'int√©rieur.

- Lancez le service (pour le moment mono-conteneur) avec `docker-compose up` (cette commande sous-entend `docker-compose build`)
- Visitez la page web de l'app.

- Ajoutons maintenant un deuxi√®me conteneur. Nous allons tirer parti d'une image d√©j√† cr√©√©e qui permet de r√©cup√©rer une "identicon". Ajoutez √† la suite du fichier Compose **_(attention aux indentations !)_**¬†:

```yml
dnmonster:
  image: amouat/dnmonster:1.0
```

Le `docker-compose.yml` doit pour l'instant ressembler √† √ßa :

```yml
version: "3.7"
services:
  identidock:
    build: .
    ports:
      - "9090:9090"

  dnmonster:
    image: amouat/dnmonster:1.0
```

Enfin, nous d√©clarons aussi un r√©seau appel√© `identinet` pour y mettre les deux conteneurs de notre application.

- Il faut d√©clarer ce r√©seau √† la fin du fichier (notez que l'on doit sp√©cifier le driver r√©seau) :

```yaml
networks:
  identinet:
    driver: bridge
```

- Il faut aussi mettre nos deux services `identidock` et `dnmonster` sur le m√™me r√©seau en ajoutant **deux fois** ce bout de code o√π c'est n√©cessaire **_(attention aux indentations !)_** :

```yaml
networks:
  - identinet
```

- Ajoutons √©galement un conteneur `redis` **_(attention aux indentations !)_**. Cette base de donn√©es sert √† mettre en cache les images et √† ne pas les recalculer √† chaque fois.

```yml
redis:
  image: redis
  networks:
    - identinet
```

`docker-compose.yml` final :

```yaml
version: "3.7"
services:
  identidock:
    build: .
    ports:
      - "9090:9090"
    networks:
      - identinet

  dnmonster:
    image: amouat/dnmonster:1.0
    networks:
      - identinet

  redis:
    image: redis
    networks:
      - identinet

networks:
  identinet:
    driver: bridge
```

- Lancez l'application et v√©rifiez que le cache fonctionne en chercheant les `cache miss` dans les logs de l'application.

- N'h√©sitez pas √† passer du temps √† explorer les options et commandes de `docker-compose`, ainsi que [la documentation officielle du langage des Compose files](https://docs.docker.com/compose/compose-file/). Cette documentation indique aussi les diff√©rences entre la version 2 et la version 3 des fichiers Docker Compose.

<!-- ## Le Docker Compose de `microblog` -->

<!-- Cr√©ons un fichier Docker Compose pour faire fonctionner [l'application Flask finale du TP pr√©c√©dent](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-xix-deployment-on-docker-containers) (√† cloner avec `git clone https://github.com/uptime-formation/microblog`) avec MySQL. -->

<!-- Refaire plut√¥t avec un wordpress, un ELK, un nextcloud, et le microblog, et traefik, recentraliser les logs -->

<!-- Nous allons ensuite installer le reverse proxy Traefik pour acc√©der √† ces services. -->

<!-- On se propose ici d'essayer de d√©ployer plusieurs services pr√©-configur√©s comme le microblog, et d'installer le reverse proxy Traefik pour acc√©der √† ces services. -->

## D'autres services

### Exercice de *google-fu* : un pad CodiMD

<!-- On se propose ici d'essayer de d√©ployer plusieurs services pr√©-configur√©s comme Wordpress, Nextcloud ou votre logiciel pr√©f√©r√©. -->

- R√©cup√©rez (et adaptez si besoin) √† partir d'Internet un fichier `docker-compose.yml` permettant de lancer un pad CodiMD avec sa base de donn√©es. Je vous conseille de toujours chercher **dans la documentation officielle** ou le repository officiel (souvent sur Github) en premier. Attention, CodiMD avant s'appelait **HackMD**.

- V√©rifiez que le pad est bien accessible sur le port donn√©.

<!-- Assemblez √† partir d'Internet un fichier `docker-compose.yml` permettant de lancer un Wordpress et un Nextcloud **d√©j√† pr√©-configur√©s** (pour l'acc√®s √† la base de donn√©es notamment). Ajoutez-y un pad CodiMD / HackMD (toujours gr√¢ce √† du code trouv√© sur Internet). -->

## Une stack Elastic

### Centraliser les logs

L'utilit√© d'Elasticsearch est que, gr√¢ce √† une configuration tr√®s simple de son module Filebeat, nous allons pouvoir centraliser les logs de tous nos conteneurs Docker.
Pour ce faire, il suffit d'abord de t√©l√©charger une configuration de Filebeat pr√©vue √† cet effet :

```bash
curl -L -O https://raw.githubusercontent.com/elastic/beats/7.10/deploy/docker/filebeat.docker.yml
```

Renommons cette configuration et rectifions qui poss√®de ce fichier pour satisfaire une contrainte de s√©curit√© de Filebeat :

```bash
mv filebeat.docker.yml filebeat.yml
sudo chown root filebeat.yml
```

Enfin, cr√©ons un fichier `docker-compose.yml` pour lancer une stack Elasticsearch :

```yaml
version: "3"

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.5.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    networks:
      - logging-network

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.5.0
    user: root
    depends_on:
      - elasticsearch
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - logging-network
    environment:
      - -strict.perms=false

  kibana:
    image: docker.elastic.co/kibana/kibana:7.5.0
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601
    networks:
      - logging-network

networks:
  logging-network:
    driver: bridge
```

Il suffit ensuite de se rendre sur Kibana (port `5601`) et de configurer l'index en tapant `*` dans le champ indiqu√©, de valider et de s√©lectionner le champ `@timestamp`, puis de valider. L'index n√©cessaire √† Kibana est cr√©√©, vous pouvez vous rendre dans la partie Discover √† gauche (l'ic√¥ne boussole üß≠) pour lire vos logs.

<!-- ### _Facultatif :_ Ajouter un n≈ìud Elasticsearch

Puis, √† l'aide de la documentation Elasticsearch et/ou en adaptant de bouts de code Docker Compose trouv√©s sur internet, ajoutez et configurez un n≈ìud Elastic. Toujours √† l'aide de la documentation Elasticsearch, v√©rifiez que ce nouveau n≈ìud communique bien avec le premier. -->


<!-- ### _Facultatif_ : ajouter une stack ELK √† `microblog` -->
<!-- TODO: Fiare avec ma version de l'app et du docker compose -->
<!-- Dans la derni√®re version de l'app `microblog`, Elasticsearch est utilis√© pour fournir une fonctionnalit√© de recherche puissante dans les posts de l'app.
Avec l'aide du [tutoriel de Miguel Grinberg](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-xix-deployment-on-docker-containers), √©crivez le `docker-compose.yml` qui permet de lancer une stack enti√®re pour `microblog`. Elle devra contenir un conteneur `microblog`, un conteneur `mysql`, un conteneur `elasticsearch` et un conteneur `kibana`. -->

<!-- ### _Facultatif / avanc√©_ : centraliser les logs de microblog sur ELK

Avec la [documentation de Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-autodiscover.html) et des [hints Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-autodiscover-hints.html) ainsi que gr√¢ce √† [cette page](https://discuss.elastic.co/t/nginx-filebeat-elk-docker-swarm-help/130512/2), trouvez comment centraliser les logs Flask de l'app `microblog` gr√¢ce au syst√®me de labels Docker de Filebeat.

Tentons de centraliser les logs de
de ces services dans ELK. -->

<!-- ### Un `docker-compose.prod.yml` pour `identicon`

#### Faire varier la configuration en fonction de l'environnement

Finalement le serveur de d√©veloppement flask est bien pratique pour debugger en situation de d√©veloppement, mais il n'est pas adapt√© √† la production.
Nous pourrions cr√©er deux images pour les deux situations mais ce serait aller contre l'imperatif DevOps de rapprochement du d√©v et de la production.

- Cr√©ons un script bash `boot.sh` pour adapter le lancement de l'application au contexte:

```bash
#!/bin/bash
set -e
if [ "$CONTEXT" = 'DEV' ]; then
    echo "Running Development Server"
    exec python3 "/app/identidock.py"
else
    echo "Running Production Server"
    exec uwsgi --http 0.0.0.0:9090 --wsgi-file /app/identidock.py --callable app --stats 0.0.0.0:9191
fi
```

- Ajoutez au Dockerfile une deuxi√®me instruction `COPY` en dessous de la pr√©c√©dente pour mettre le script dans le conteneur.
- Ajoutez un `RUN chmod a+x /boot.sh` pour le rendre executable.
- Modifiez l'instruction `CMD` pour lancer le script de boot plut√¥t que `uwsgi` directement.
- Modifiez l'instruction expose pour d√©clarer le port 5000 en plus.
- Ajoutez au dessus une instruction `ENV ENV PROD` pour d√©finir la variable d'environnement `ENV` √† la valeur `PROD` par d√©faut.

- Testez votre conteneur en mode DEV avec `docker run --env CONTEXT=DEV -p 5000:5000 identidock`, visitez localhost:5000
- Et en mode `PROD` avec `docker run --env CONTEXT=PROD -p 9090:9090 identidock`. Visitez localhost:9090.

{{% expand "Solution `Dockerfile`:" %}}

```Dockerfile
FROM python:3.7
RUN groupadd -r uwsgi && useradd -r -g uwsgi uwsgi
RUN pip install Flask uWSGI requests redis
WORKDIR /app
COPY app /app
COPY boot.sh /
RUN chmod a+x /boot.sh
ENV CONTEXT PROD
EXPOSE 9090 9191 5000
USER uwsgi
CMD ["/boot.sh"]
```

{{% /expand %}}

Conclusions:

- On peut faire des images multicontextes qui s'adaptent au contexte.
- Les variables d'environnement sont souvent utilis√©e pour configurer les conteneurs au moment de leur lancement. (plus dynamique qu'un fichier de configuration)

#### Un `docker-compose.prod.yml` pour `identicon`

- Cr√©ez un deuxi√®me fichier Compose `docker-compose.prod.yml` (√† compl√©ter) pour lancer l'application `identicon` en configuration de production. Que doit-on penser √† adapter ?

{{% expand "Solution `docker-compose.prod.yml` :" %}}

```yaml
version: "3"
services:
  identidock:
    image: <votre_hub_login>/identidock:0.1
    ports:
      - "9090:9090"
      - "9191:9191"
    environment:
      - CONTEXT=PROD
    networks:
      - identinet

  dnmonster:
    image: amouat/dnmonster:1.0
    networks:
      - identinet

  redis:
    image: redis
    networks:
      - identinet
    volumes:
      - identiredis_volume:/data

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    networks:
      - identinet

networks:
  identinet:
    driver: bridge

volumes:
  identiredis_volume:
    driver: local
```


{{% /expand %}}


Commentons ce code:

- plus de volume `/app` pour `identidock` car nous sommes en prod
- on ouvre le port de l'app `9090` mais aussi le port de stat du serveur uWSGI `9191`
- `CONTEXT=PROD` pour lancer l'application avec le serveur uWSGI
- On a mis un volume nomm√© √† `redis` pour conserver les donn√©es sur le long terme
- on a ajout√© un GUI web Redis accessible sur `localhost:8081` pour voir le conteneur de la base de donn√©es Redis
- le tout dans le m√™me r√©seau

Le d√©p√¥t avec les solutions : <https://github.com/Uptime-Formation/tp4_docker_compose_correction_202001>

--- -->


<!-- Galera automagic docker-compose : https://gist.github.com/lucidfrontier45/497341c4b848dfbd6dfb -->

### _Facultatif :_ Utiliser Traefik

Vous pouvez d√©sormais faire [l'exercice 1 du TP7](../7-tp-traefik) pour configurer un serveur web qui permet d'acc√©der √† vos services via des domaines.

<!-- ### *Facultatif :* du monitoring avec *cAdvisor* et *Prometheus*

Suivre ce tutoriel pour du monitoring des conteneurs Docker : <https://prometheus.io/docs/guides/cadvisor/> -->